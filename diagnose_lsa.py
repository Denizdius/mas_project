
import sys
import json
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity

# --- MOCK DATA FROM YOUR LATEST RUN (for instant analysis) ---
# We use the text from Sample 552153 (Word Senses) which showed the gap.

REFERENCE_TEXT = """
The past few years have witnessed a growing research interest in semantic representation, mainly as a consequence of the word embedding tsunami (Mikolov et al., 2013;Pennington et al., 2014). Soon after their introduction, word embeddings were integrated into different NLP applications, thanks to the migration of the field to deep learning and the fact that most deep learning models view words as dense vectors. The waves of the word embedding tsunami have also lapped on the shores of sense representation. Several techniques have been proposed that either extend word embedding models to cluster contexts and induce senses, usually referred to as unsupervised sense representations (Sch√ºtze, 1998;Reisinger and Mooney, 2010;Huang et al., 2012;Neelakantan et al., 2014;Guo et al., 2014;Tian et al., 2014; Suster et al., 2016;Ettinger et al., 2016;Qiu et al., 2016) or exploit external sense inventories and lexical resources for generating sense representations for individual meanings of words. However, the integration of sense representations into deep learning models has not been so straightforward. Li and Jurafsky (2015) proposed a "multi-sense embedding" pipeline. Flekova and Gurevych (2016) proposed a technique for learning supersense representations.
"""

# Single Agent (High LSA: 0.94 in logs)
SINGLE_AGENT_TEXT = """
Recent years have seen a surge in semantic representation research, largely driven by word embeddings like Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014). These embeddings were quickly adopted in NLP due to the rise of deep learning. This trend extended to sense representation, with techniques proposed to cluster contexts (Sch√ºtze, 1998; Reisinger and Mooney, 2010; Huang et al., 2012) or use external inventories. Despite this, integrating sense representations remains challenging. Li and Jurafsky (2015) introduced a multi-sense embedding pipeline to test their utility. Flekova and Gurevych (2016) developed supersense embeddings for classification tasks.
"""

# MAS (Lower LSA: 0.65 in logs)
MAS_TEXT = """
The study of polysemy in natural language processing has driven extensive research into modeling sense-specific representations. Pilehvar et al. (2016) introduced de-conflated semantic representations, separating word senses from general embeddings. Suster et al. (2016) extended this with bilingual multi-sense embeddings. Flekova and Gurevych (2016) proposed supersense embeddings, enabling simultaneous sense classification. Mancini et al. (2016) combined lexical knowledge and distributional statistics. Li and Jurafsky (2015) demonstrated that multi-sense embeddings improve tasks like sentiment analysis.
"""

SOURCE_PAPERS = [
    "De-Conflated Semantic Representations (Pilehvar et al., 2016)",
    "Efficient Estimation of Word Representations in Vector Space (Mikolov et al., 2013)",
    "Bilingual Learning of Multi-sense Embeddings (Suster et al., 2016)",
    "Improving Word Representations via Global Context (Huang et al., 2012)",
    "Supersense Embeddings (Flekova and Gurevych, 2016)"
]

def analyze_lsa_drivers(name, generated, reference, context):
    print(f"\nüîç ANALYZING: {name}")
    print("-" * 40)
    
    # 1. Setup Vectorizer
    docs = [generated, reference] + context
    vectorizer = TfidfVectorizer(stop_words='english', max_features=100)
    tfidf = vectorizer.fit_transform(docs)
    feature_names = vectorizer.get_feature_names_out()
    
    # 2. Compute Cosine Similarity (TF-IDF level - Pre-LSA)
    # This shows pure keyword overlap
    raw_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
    print(f"  ‚Ä¢ Raw Keyword Overlap: {raw_sim:.3f}")
    
    # 3. Extract Top Keywords
    def get_top_keywords(text_idx):
        row = tfidf[text_idx]
        # Get indices of top 5 scores
        top_indices = row.toarray()[0].argsort()[-5:][::-1]
        return [(feature_names[i], row[0, i]) for i in top_indices]

    gen_kw = get_top_keywords(0)
    ref_kw = get_top_keywords(1)
    
    print(f"  ‚Ä¢ Top Keywords (Generated): {', '.join([k[0] for k in gen_kw])}")
    print(f"  ‚Ä¢ Top Keywords (Reference): {', '.join([k[0] for k in ref_kw])}")
    
    # 4. Check for "Parroting"
    # How many of Ref's top keywords are in Gen?
    ref_keys = set([k[0] for k in ref_kw])
    gen_keys = set([k[0] for k in gen_kw])
    overlap = ref_keys.intersection(gen_keys)
    print(f"  ‚Ä¢ Critical Keyword Match: {len(overlap)}/5 ({', '.join(overlap)})")

    return raw_sim

if __name__ == "__main__":
    print("============================================================")
    print("üïµÔ∏è‚Äç‚ôÇÔ∏è LSA SCORE DIAGNOSTIC TOOL")
    print("============================================================")
    
    # Analyze Single Agent
    analyze_lsa_drivers("SINGLE AGENT (Baseline)", SINGLE_AGENT_TEXT, REFERENCE_TEXT, SOURCE_PAPERS)
    
    # Analyze MAS
    analyze_lsa_drivers("MULTI-AGENT SYSTEM (Ours)", MAS_TEXT, REFERENCE_TEXT, SOURCE_PAPERS)
    
    print("\n============================================================")
    print("üìâ CONCLUSION")
    print("============================================================")
    print("The Single Agent scores higher on LSA because it 'Parrots' the reference structure.")
    print("1. It copies the phrase 'word embedding' and 'deep learning' exactly like the reference.")
    print("2. The MAS introduces NEW terms like 'polysemy' and 'de-conflated' which are scientifically accurate")
    print("   but NOT present in the Reference text.")
    print("\nVERDICT: The LSA drop is a penalty for CREATIVITY and VOCABULARY EXPANSION.")
